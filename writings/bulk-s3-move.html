<!DOCTYPE html>
<html>
<head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />

    <title>James Gregory</title>
    <meta name="description" content="I like turtles.
" />

    <meta name="HandheldFriendly" content="True" />
    <meta name="MobileOptimized" content="320" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />

    <link rel="stylesheet" type="text/css" href="/css/screen.css" />
    <link rel="stylesheet" type="text/css" href="//fonts.googleapis.com/css?family=Merriweather:300,700,700italic,300italic|Open+Sans:700,400" />
    <!-- Customisation  -->
    <link rel="stylesheet" type="text/css" href="/css/main.css" />

</head>
<body class="home-template">

    <header class="main-header post-head no-cover">
    <nav class="main-nav  clearfix">
        <a class="back-button icon-arrow-left" href="/">Home</a>
    </nav>
</header>

<main class="content" role="main">

    <article class="post">

        <header class="post-header">
            <h1 class="post-title">The anatomy of a quick bash script (bulk rename Kinesis Firehose files in S3)</h1>
            <section class="post-meta">
                <time class="post-date" datetime="2020-07-21">21 Jul 2020</time>
                
            </section>
        </header>

        <section class="post-content">
            <blockquote>
  <p><strong>Also known as</strong>: how to move hundreds of files in S3 that you accidentally put in the wrong place because you misconfigured a Kinesis Firehose.</p>
</blockquote>

<!-- more -->

<p>I have a Kinesis Firehose streaming change capture data into an S3 bucket so I can query it using Athena. This has been working great for months, but I just realised the default configuration of Firehose does not put the files in a structure that Athena can partition on, so my Athena queries are scanning the entire dataset instead of partitioning on date.</p>

<p>Kinesis Firehose by default delivers files in a structure like: <code class="language-plaintext highlighter-rouge">2020/07/20/16/Filename-2020-07-20-16-00-00-hash</code>. But Athena wants files in a structure compatible with Hive’s partition format, which uses a variable-based convention: <code class="language-plaintext highlighter-rouge">year=2020/month=07/day=20/hour=16/Filename-2020-07-20-16-00-00-hash</code></p>

<p>In my case, I’ve decided having the hour in the path is making my partitions too small (not enough data per-hour) so I’m going to use a structure of just the date as a single variable: <code class="language-plaintext highlighter-rouge">dt=2020-07-20/Filename-2020-07-20-16-00-00-hash</code>.</p>

<p>Now I just need to move hundreds of files from the old structure into the new structure!</p>

<h2 id="the-commands">The commands</h2>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>aws s3 <span class="nb">ls</span> <span class="nt">--recursive</span> s3://bucket-name/ <span class="se">\</span>
  | <span class="nb">awk</span> <span class="s1">'{ print $4 }'</span> <span class="se">\</span>
  | <span class="nb">sed</span> <span class="nt">-E</span> <span class="s2">"p;s/([0-9]{4})</span><span class="se">\/</span><span class="s2">([0-9]{2})</span><span class="se">\/</span><span class="s2">([0-9]{2})</span><span class="se">\/</span><span class="s2">[0-9]{2}/dt=</span><span class="se">\1</span><span class="s2">-</span><span class="se">\2</span><span class="s2">-</span><span class="se">\3</span><span class="s2">/"</span> <span class="se">\</span>
  | <span class="nb">sed</span> <span class="nt">-E</span> <span class="s2">"s/^/s3:</span><span class="se">\/\/</span><span class="s2">bucket-name</span><span class="se">\/</span><span class="s2">/"</span> <span class="se">\</span>
  | xargs <span class="nt">-n2</span> aws s3 <span class="nb">mv</span>
</code></pre></div></div>

<p>Running this script will move all files from <code class="language-plaintext highlighter-rouge">s3://bucket-name/year/month/day/hour/filename</code> to <code class="language-plaintext highlighter-rouge">s3://bucket-name/dt=year-month-day/filename</code>.</p>

<blockquote>
  <p>Note: this is not particularly elegant: you could likely combine several of these lines together but I’ve favoured readability over efficiency, and it’s also not particularly fast so probably don’t use it for millions of files.</p>
</blockquote>

<h2 id="the-breakdown">The breakdown</h2>

<p>Start by listing all the files in the bucket:</p>

<p><code class="language-plaintext highlighter-rouge">aws s3 ls --recursive s3://bucket-name</code></p>

<p>This produces an output like:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>2020-07-16 15:12:29 10016 2020/07/16/05/Snapshot-2020-07-16-05-07-26
2020-07-17 09:21:12 10838 2020/07/16/23/Snapshot-2020-07-16-23-16-10
2020-07-17 09:27:52  5790 2020/07/16/23/Snapshot-2020-07-16-23-22-50
2020-07-17 09:55:43  5409 2020/07/16/23/Snapshot-2020-07-16-23-50-41
</code></pre></div></div>

<blockquote>
  <p>I’m truncating the filenames in this post just to make it a bit more readable. Imagine there being
a hash at the end of each line too.</p>
</blockquote>

<p>Next, extract just the filename from the output, which is the 4th column:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">awk</span> <span class="s1">'{ print $4 }'</span>
</code></pre></div></div>

<blockquote>
  <p>I’m using <code class="language-plaintext highlighter-rouge">awk</code> here because <code class="language-plaintext highlighter-rouge">cut</code> doesn’t deal well with space delimited columns and <code class="language-plaintext highlighter-rouge">aws s3 ls</code> doesn’t let you control the output format. If the output was tab delimited <code class="language-plaintext highlighter-rouge">cut</code> would’ve worked too.</p>
</blockquote>

<p>This produces an output of just the filenames:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>2020/07/16/05/Snapshot-2020-07-16-05-07-26
2020/07/16/23/Snapshot-2020-07-16-23-16-10
2020/07/16/23/Snapshot-2020-07-16-23-22-50
2020/07/16/23/Snapshot-2020-07-16-23-50-41
</code></pre></div></div>

<p>Next is the fun part. We need to take that filename and transform it into our new format <em>whilst also preserving the original filename so both can be passed to a move command together</em>. <code class="language-plaintext highlighter-rouge">sed</code> works well for this:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">sed</span> <span class="nt">-E</span> <span class="s2">"p;s/([0-9]{4})</span><span class="se">\/</span><span class="s2">([0-9]{2})</span><span class="se">\/</span><span class="s2">([0-9]{2})</span><span class="se">\/</span><span class="s2">[0-9]{2}/dt=</span><span class="se">\1</span><span class="s2">-</span><span class="se">\2</span><span class="s2">-</span><span class="se">\3</span><span class="s2">/"</span>
</code></pre></div></div>

<p>It’s a pretty dense command, but most of that is a regular expression. To break it down:</p>

<ol>
  <li><code class="language-plaintext highlighter-rouge">-E</code> enable extended regular expressions, this gives us the <code class="language-plaintext highlighter-rouge">()</code> group match support.</li>
  <li><code class="language-plaintext highlighter-rouge">p;</code> you might not see this part very often, this prints the input as well as the replacement, so for one line in you get two lines out: the original, and whatever the replacement produced. This is key for being able to build the move command easily later as it requires a source and a destination.</li>
  <li><code class="language-plaintext highlighter-rouge">s/</code> start the regular expression.</li>
  <li><code class="language-plaintext highlighter-rouge">([0-9]{4})\/([0-9]{2})\/([0-9]{2})\/[0-9]{2}</code> match the <code class="language-plaintext highlighter-rouge">year/month/day/hour</code> part of the path, capturing the year, month, and day as groups so they can be reused later.</li>
  <li><code class="language-plaintext highlighter-rouge">/dt=\1-\2-\3</code> specify the replacement; we replace the whole match (year/month/day/hour) with a pattern of <code class="language-plaintext highlighter-rouge">dt=year-month-day</code> where <code class="language-plaintext highlighter-rouge">\1</code>, <code class="language-plaintext highlighter-rouge">\2</code>, and <code class="language-plaintext highlighter-rouge">\3</code> are references to the capture groups in the regular expression.</li>
</ol>

<blockquote>
  <p>Optimisation: This could probably have done in our previous <code class="language-plaintext highlighter-rouge">awk</code> command which has regular expression support, but it was looking pretty ugly and I’d prefer to waste a few CPU cycles than bend my brain too much.</p>
</blockquote>

<p>The output now looks like this:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>2020/07/16/05/Snapshot-2020-07-16-05-07-26
dt=2020-07-16/Snapshot-2020-07-16-05-07-26
2020/07/16/23/Snapshot-2020-07-16-23-16-10
dt=2020-07-16/Snapshot-2020-07-16-23-16-10
2020/07/16/23/Snapshot-2020-07-16-23-22-50
dt=2020-07-16/Snapshot-2020-07-16-23-22-50
2020/07/16/23/Snapshot-2020-07-16-23-50-41
dt=2020-07-16/Snapshot-2020-07-16-23-50-41
</code></pre></div></div>

<p>You’ll notice there are twice as many lines now, due to the <code class="language-plaintext highlighter-rouge">p;</code> setting of <code class="language-plaintext highlighter-rouge">sed</code>. For each original line there’s now that line plus the reformatted line.</p>

<p>Next up is to prefix each line with the bucket name. The move command expects all filenames to be fully-qualified with their bucket:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">sed</span> <span class="nt">-E</span> <span class="s2">"s/^/s3:</span><span class="se">\/\/</span><span class="s2">bucket-name</span><span class="se">\/</span><span class="s2">/"</span>
</code></pre></div></div>

<blockquote>
  <p>Optimisation: With some smarter regular expressions, this could’ve been folded into the previous <code class="language-plaintext highlighter-rouge">sed</code> statement.</p>
</blockquote>

<p>The output now looks like this:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>s3://bucket-name/2020/07/16/05/Snapshot-2020-07-16-05-07-26
s3://bucket-name/dt=2020-07-16/Snapshot-2020-07-16-05-07-26
s3://bucket-name/2020/07/16/23/Snapshot-2020-07-16-23-16-10
s3://bucket-name/dt=2020-07-16/Snapshot-2020-07-16-23-16-10
s3://bucket-name/2020/07/16/23/Snapshot-2020-07-16-23-22-50
s3://bucket-name/dt=2020-07-16/Snapshot-2020-07-16-23-22-50
s3://bucket-name/2020/07/16/23/Snapshot-2020-07-16-23-50-41
s3://bucket-name/dt=2020-07-16/Snapshot-2020-07-16-23-50-41
</code></pre></div></div>

<p>The same as before, but now prefixed with the bucket name.</p>

<p>One final step to go, the actual move:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>xargs <span class="nt">-n2</span> aws s3 <span class="nb">mv</span>
</code></pre></div></div>

<p>We use xargs (an absolute cornerstone of shell scripting) to execute the <code class="language-plaintext highlighter-rouge">aws s3 mv</code> command and finish the job. Let’s break this one down too:</p>

<ol>
  <li><code class="language-plaintext highlighter-rouge">xargs</code> reads from stdin and executes a command with the stdin lines as arguments. So <code class="language-plaintext highlighter-rouge">echo hi | xargs cowsay</code> is the equivalent to <code class="language-plaintext highlighter-rouge">cowsay hi</code>. In our case, we take the filenames we’ve been processing and pass them to <code class="language-plaintext highlighter-rouge">aws s3 mv</code> as arguments.</li>
  <li><code class="language-plaintext highlighter-rouge">-n2</code> this tells xargs to take <em>two lines</em> instead of just one, and pass them both to our command. Because we have one line with the original and a second line with the transformed, <code class="language-plaintext highlighter-rouge">xargs</code> calls the move command like so: <code class="language-plaintext highlighter-rouge">aws s3 mv original-line transformed-line</code>, which is exactly what’s need to move a file from one place to another.</li>
  <li><code class="language-plaintext highlighter-rouge">aws s3 mv</code> as already mentioned, is the command <code class="language-plaintext highlighter-rouge">xargs</code> is going to call.</li>
</ol>

<p>Running that command will take a list of original filenames, transform them into pairs of original and transformed filenames, prepend the filenames with the bucket, and then pass the pairs to <code class="language-plaintext highlighter-rouge">aws s3 mv</code>.</p>

<p>And that’s it, done! Files moved.</p>


        </section>

        

        <footer class="post-footer">
            <!-- If we want to display author's name and bio -->
            

            
        </footer>
    </article>
</main>

    <footer class="site-footer clearfix">
      <section class="copyright">
        <a href="mailto:james@jagregory.com">James Gregory</a> &copy;
              2021 &bull; All content licensed under <a href="http://creativecommons.org/licenses/by-nc-sa/4.0/">cc by-nc-sa 4.0</a>.
      </section>
    </footer>

    <script type="text/javascript" src="/js/jquery-1.11.1.min.js"></script>
    <script type="text/javascript" src="/js/jquery.fitvids.js"></script>
    <script type="text/javascript" src="/js/index.js"></script>
</body>
</html>
